{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "1. This project dealt with localization part of SLAM, as we had to optimize for the pose given the odometery and loop closure constraints. The Mapping part of the SLAM is dealt in different ways. With the help of LIDAR scans we can get 3D point clouds of the 3D environment. we can perform Iterative Closest Point Algorithm to perform the Data Assciation of the Maps at various poses. With the help of RGB-D Video stream we can determine the 3D point in the world based on the Depth information and the Camera Instrinsics.\n",
    "\n",
    "2. Loop closure can be detected using GPS information or by using visual features of images from RGB camera. Specifically, given two frames we can compute the similarity between them by computing similarity/distance between the features corresponding to them when passed through a deep learning based visual feature extractor.\n",
    "\n",
    "3. Jacobian is sparse 2D matrix, with left half corresponding to localization and right half corresponding to mapping. In this project, we only use the jacobian associated with localization part. The pose graph is not fully connected as we do not have edges between each pose pair. Generally each pose depends on its previous or following pose. There can exist cases where loop closures exist the poses gets connected to non successive poses. Inspite of Loop closures the pose graphs are not fully connected.\n",
    "\n",
    "4. * The SLAM Backend which involves optimization of the pose estimations(pose graphs). We call this SLAM Backend because the quantities that are needed to construct the pose graph like the Nodes(poses) and edges(constraints) are given in the problem. Opitimization techniques like LM,Gauss Newton are used to minimize the error between the observed and predicted poses/Nodes.\n",
    "   * The SLAM Frontend involves data association (mapping), processing sensor data and construction of graphs with Landmarks which are determined during the backend phase of SLAM. It determines the positions of the Landmarks/3D environment. \n",
    "   * We need to optimize our poses/map because of the inherent noise in the sensor data, the graphs constructed in Frontend part of SLAM can have errors like false positive loop closures that gets carried to the Backend part of SLAM. These errors can even get reflected in the Backend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebb025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
